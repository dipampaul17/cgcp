"""
Exploitation Risk Detection Tagger
Identifies potential malicious use, fraud, and exploitation patterns
Based on cybersecurity and fraud prevention guidelines
"""

import re
from backend.taggers.base_tagger import RiskTagger, RiskScore


class ExploitationTagger(RiskTagger):
    """Detects exploitation and malicious use patterns"""
    
    def __init__(self):
        super().__init__("exploitation")
        
        self.patterns = [
            # Cyber attacks and hacking
            (r"(hack|breach|exploit).{0,30}(system|network|server|database|website)", 0.85, "hacking_intent"),
            (r"(SQL injection|XSS|CSRF|buffer overflow|zero.?day)", 0.8, "attack_technique"),
            (r"(backdoor|rootkit|keylogger|malware|ransomware).{0,30}(create|develop|deploy)", 0.9, "malware_development"),
            (r"(phishing|spear.?phishing).{0,30}(email|campaign|template|create)", 0.85, "phishing_creation"),
            (r"(password|credential).{0,30}(crack|steal|harvest|dump)", 0.8, "credential_theft"),
            
            # Financial fraud
            (r"(credit card|bank account).{0,30}(fraud|steal|clone|skim)", 0.9, "financial_fraud"),
            (r"(launder|laundering).{0,30}(money|funds|crypto|bitcoin)", 0.85, "money_laundering"),
            (r"(fake|counterfeit).{0,30}(ID|passport|document|license)", 0.85, "document_fraud"),
            (r"(pyramid|ponzi).{0,20}(scheme|scam)", 0.8, "investment_fraud"),
            
            # Social engineering
            (r"(manipulate|trick|deceive).{0,30}(people|person|victim).{0,30}(into)", 0.75, "social_engineering"),
            (r"(impersonate|pretend to be).{0,30}(official|authority|bank|government)", 0.8, "impersonation"),
            (r"(romance|dating).{0,20}(scam|fraud)", 0.75, "romance_scam"),
            
            # Harassment and stalking
            (r"(stalk|harass|intimidate|threaten).{0,30}(someone|person|individual)", 0.85, "harassment"),
            (r"(dox|doxx|doxxing).{0,30}(someone|person|find address)", 0.9, "doxxing"),
            (r"(revenge porn|intimate images).{0,30}(share|distribute|post)", 0.95, "revenge_porn"),
            
            # Illegal services
            (r"(hire|find).{0,30}(hitman|assassin|killer)", 0.95, "violence_services"),
            (r"(buy|purchase|acquire).{0,30}(drugs|narcotics|illegal substances).{0,30}(online|dark web)", 0.85, "illegal_purchases"),
            (r"(fake|forge).{0,30}(prescription|medical|doctor).{0,20}(note|certificate)", 0.8, "medical_fraud"),
            
            # Misinformation campaigns
            (r"(spread|create|generate).{0,30}(misinformation|disinformation|fake news)", 0.7, "misinformation"),
            (r"(bot|botnet).{0,30}(create|deploy|manage).{0,30}(social media|twitter|facebook)", 0.8, "bot_creation"),
            (r"(deepfake|deep fake).{0,30}(create|make|generate)", 0.85, "deepfake_creation"),
        ]
        
        self.context_patterns = [
            (r"(security|cybersecurity).{0,30}(research|education|awareness)", -0.3, "security_education"),
            (r"(protect|defend|prevent).{0,30}(against|from)", -0.25, "defensive_context"),
            (r"(ethical hacking|penetration testing|bug bounty)", -0.3, "ethical_security"),
            (r"(report|reporting|journalist|documentary)", -0.2, "journalism_context"),
        ]
    
    def detect(self, prompt: str, completion: str = "") -> RiskScore:
        """Analyze text for exploitation patterns"""
        
        full_text = f"{prompt} {completion}".lower()
        
        matched_patterns = []
        pattern_weights = []
        
        # Check exploitation patterns
        for pattern, weight, description in self.patterns:
            if re.search(pattern, full_text, re.IGNORECASE):
                matched_patterns.append(description)
                pattern_weights.append((description, weight))
        
        # Check context patterns
        for pattern, weight, description in self.context_patterns:
            if re.search(pattern, full_text, re.IGNORECASE):
                pattern_weights.append((description, weight))
        
        # Calculate confidence
        confidence = self._calculate_confidence(pattern_weights)
        
        # Determine severity
        severity = "low"
        if confidence > 0.8:
            severity = "critical"
        elif confidence > 0.6:
            severity = "high"
        elif confidence > 0.4:
            severity = "medium"
        
        return RiskScore(
            category=self.category,
            confidence=confidence,
            matched_patterns=matched_patterns,
            severity=severity
        ) 